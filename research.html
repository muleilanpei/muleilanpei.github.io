<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Research Projects</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Muleilan PEI</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="background.html">Background</a></div>
<div class="menu-item"><a href="research.html" class="current">Research</a></div>
<div class="menu-item"><a href="publication.html">Publication</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Research Projects</h1>
</div>
<h2>An Improved Dyna-Q Algorithm for Mobile Robot Path Planning in Unknown Dynamic Environment </h2>
<table class="imgtable"><tr><td>
<img src="sim_dynamic.gif" alt="alt text" width="300px" height="300px" />&nbsp;</td>
<td align="left"><p><b>Abstract</b>:ddddd <br />
[<a href="https://ieeexplore.ieee.org/document/9146733/authors">Paper</a>]</p>
</td></tr></table>
<h2>Quadruped Robot Locomotion in Unknown Terrain Using Deep Reinforcement Learning</h2>
<table class="imgtable"><tr><td>
<img src="prob.png" alt="alt text" width="300px" height="210px" />&nbsp;</td>
<td align="left"><p><b>Abstract</b>:This paper is concerned with locomotion problems for the quadruped robot in unknown and unstructured terrains, utilizing the emerging deep reinforcement learning technique. The state-of-the-art deep deterministic policy gradient (DDPG) algorithm is leveraged to acquire the gait policy by learning from interactions with the environment. The framework of learning system is presented based on the actor-critic architecture, and the additional domain-specific knowledge is exploited for shaping the reward function to enhance the learning efficiency during training. Moreover, a simulation study is implemented to validate the performance of the proposed DDPG-based controller.<br />
[<a href="https://ieeexplore.ieee.org/abstract/document/9274920">Paper</a>]</p>
</td></tr></table>
</td>
</tr>
</table>
</body>
</html>
